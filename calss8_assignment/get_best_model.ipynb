{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "来自刘建平博客：https://www.cnblogs.com/pinard/p/7278324.html#!comments\n",
    "\n",
    "问：另外还有个问题想老师指导下，Tf-idf向量是针对于句子或者段落文章整体的一个特征；而word2vec只是针对某个单词或词组；\n",
    "这两者是完全不同的东西，怎么能混淆一起使用呢？对吧老师\n",
    "\n",
    "\n",
    "答：TF-IDF和Wordvec的确是完全不同的思路，要看你要解决的问题。\n",
    "如果是你要分类聚类等，就用TF-IDF更简单。如果是要找近义词这样的需求，就用word2vec更方便。\n",
    "一般不会混淆。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.743 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "dataset = pd.read_csv('../sqlResult.csv', encoding = 'gb18030')\n",
    "dataset = dataset.fillna('')\n",
    "\n",
    "is_xinhua_news = dataset[dataset['source'].str.contains('新华')]\n",
    "# print(len(is_xinhua_news)/len(dataset))   -> 88.00%\n",
    "\n",
    "dataset = dataset.sample(20000)   #考虑到调参是大数据的话，速度很慢，所以取的样本量少些。\n",
    "\n",
    "dataset['label'] = np.where(dataset['source'].str.contains('新华'),1,0)\n",
    "\n",
    "y = dataset['label'].values\n",
    "\n",
    "# def cleaner_1(string):\n",
    "#     if '新华社' in string:\n",
    "#         string.replace('新华社', '')\n",
    "#     elif '新华网' in string:\n",
    "#         string.replace('新华网', '')\n",
    "#     return string\n",
    "\n",
    "def cleaner(string): return ''.join(re.findall('[\\d|\\w]+', string))\n",
    "\n",
    "def cut(string): return ' '.join(jieba.cut(string))\n",
    "\n",
    "# news_content = dataset['content'].apply(cleaner_1)#好像cleaner_1不起作用，这是为啥？！\n",
    "news_content = dataset['content'].apply(cleaner)\n",
    "news_content = [cut(i) for i in news_content]\n",
    "\n",
    "dataset['content'] = news_content\n",
    "\n",
    "X = dataset['content'].values\n",
    "\n",
    "with open('../stop_words.txt', encoding = 'gbk') as f:\n",
    "\n",
    "    stopwords = f.read()\n",
    "\n",
    "stopwords_list = stopwords.splitlines()\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, norm='l2', min_df = 5, max_df = 0.7, ngram_range=(1, 2),stop_words=stopwords_list,max_features=35000)\n",
    "features = tfidf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TruncatedSVD 对features降维（之前试过PCA，但是报错，显示是不接收稀疏的输入），从（60000，35000）\n",
    "#降到（60000,5000）.5000还是运行时间太长了得快20min。所以改为3000.\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "features = TruncatedSVD(n_components=3000, random_state=42).fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(X))\n",
    "\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "splitpoint1 = 0.25\n",
    "\n",
    "splitpoint2 = 0.05\n",
    "\n",
    "train_indices = indices[int(len(X)*splitpoint1):]\n",
    "\n",
    "valid_indices = indices[int(len(X)*splitpoint2):int(len(X)*splitpoint1)]\n",
    "\n",
    "test_indices = indices[:int(len(X)*splitpoint2)]\n",
    "\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test = (\n",
    "                                                        features[train_indices],\n",
    "                                                        features[valid_indices],\n",
    "                                                        features[test_indices],\n",
    "                                                        y[train_indices],\n",
    "                                                        y[valid_indices],\n",
    "                                                        y[test_indices]\n",
    "\n",
    "                                                        )\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def get_performance(clf, X_, y_):\n",
    "    y_hat = clf.predict(X_)\n",
    "    print('----------{}---------'.format(model.estimator.__class__.__name__))\n",
    "    print('percision is: {}'.format(precision_score(y_, y_hat)))\n",
    "    print('recall is: {}'.format(recall_score(y_, y_hat)))\n",
    "    print('roc_auc is: {}'.format(roc_auc_score(y_, y_hat)))\n",
    "    print('confusion matrix: \\n{}'.format(confusion_matrix(y_, y_hat, labels=[0, 1])))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #还可以使用交叉验证来调参，可见例子： https://blog.csdn.net/qq_36523839/article/details/80707678\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# # from sklearn.pipeline import Pipeline\n",
    "# from sklearn.svm import SVC\n",
    "# #对LinearSVC()的错误项惩罚参数，进行搜索。\n",
    "# SVC_param_grid = {\n",
    "#     'C': [1.0, 10.0],  \n",
    "#     'kernel':['rbf', 'linear']\n",
    "# }\n",
    "\n",
    "# grid_SVC = GridSearchCV(SVC(),param_grid = SVC_param_grid,cv=5,n_jobs = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_list = [\n",
    "                         SVC(), \n",
    "                         LogisticRegression(), \n",
    "                         KNeighborsClassifier(),\n",
    "                         GaussianNB(),\n",
    "                         DecisionTreeClassifier(),\n",
    "                         \n",
    "                        ]  #可以用pipeline\n",
    "\n",
    "param_grid_list = [\n",
    "                    {'C': [1.0, 10.0],  'kernel':['rbf', 'linear']},\n",
    "                    {'C': [1.0, 10.0],'random_state':[0,42]},\n",
    "                    {'n_neighbors': [1,3,4]},\n",
    "                    {},\n",
    "                    {'splitter': ['random', 'best'], \n",
    "                     'class_weight': [{0:5,1:4},{0:5.5, 1:3.5}]}\n",
    "                   \n",
    "                  ]\n",
    "\n",
    "grid_res_list = []\n",
    "for i in range(len(param_grid_list)) :\n",
    "    grid_res = GridSearchCV(\n",
    "                            machine_learning_list[i], \n",
    "                            param_grid = param_grid_list[i],\n",
    "                            cv = 5,\n",
    "                            n_jobs = -1\n",
    "                            )\n",
    "    grid_res_list.append(grid_res)\n",
    "\n",
    "#KNN: https://www.jianshu.com/p/871884bb4a75\n",
    "#SVM： https://www.cnblogs.com/pinard/p/6117515.html\n",
    "#MultinomialNB(): https://blog.csdn.net/nc514819873/article/details/89302245\n",
    "#                https://blog.csdn.net/mr_muli/article/details/84480592\n",
    "#DecisionTreeClassifier: https://blog.csdn.net/qq_38923076/article/details/82931340"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10.0, 'kernel': 'linear'} 0.9829333333333333\n",
      "{'C': 10.0, 'random_state': 0} 0.9834\n",
      "{'n_neighbors': 3} 0.6302666666666666\n",
      "{} 0.8052\n",
      "{'class_weight': {0: 5.5, 1: 3.5}, 'splitter': 'best'} 0.9078666666666667\n"
     ]
    }
   ],
   "source": [
    "for i in grid_res_list:\n",
    "    i.fit(X_train, y_train)\n",
    "    print(i.best_params_, i.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_SVC= grid_res_list[0]\n",
    "grid_LR= grid_res_list[1]\n",
    "grid_KNN = grid_res_list[2]\n",
    "grid_NB = grid_res_list[3]\n",
    "grid_tree = grid_res_list[4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LogisticRegression'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_LR.estimator.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------SVC---------\n",
      "percision is: 0.9976520487767931\n",
      "recall is: 0.9968215528984411\n",
      "roc_auc is: 0.989732165027048\n",
      "confusion matrix: \n",
      "[[ 1755    31]\n",
      " [   42 13172]]\n",
      "\n",
      "\n",
      "----------LogisticRegression---------\n",
      "percision is: 0.993896006028636\n",
      "recall is: 0.998108067201453\n",
      "roc_auc is: 0.9763776618202114\n",
      "confusion matrix: \n",
      "[[ 1705    81]\n",
      " [   25 13189]]\n",
      "\n",
      "\n",
      "----------KNeighborsClassifier---------\n",
      "percision is: 0.9967748647523929\n",
      "recall is: 0.7250643257151506\n",
      "roc_auc is: 0.8538535514354028\n",
      "confusion matrix: \n",
      "[[1755   31]\n",
      " [3633 9581]]\n",
      "\n",
      "\n",
      "----------GaussianNB---------\n",
      "percision is: 0.9788542151839776\n",
      "recall is: 0.7952171938852732\n",
      "roc_auc is: 0.8340587649157609\n",
      "confusion matrix: \n",
      "[[ 1559   227]\n",
      " [ 2706 10508]]\n",
      "\n",
      "\n",
      "----------DecisionTreeClassifier---------\n",
      "percision is: 0.9853485386300128\n",
      "recall is: 0.9873618889057061\n",
      "roc_auc is: 0.9393696342624834\n",
      "confusion matrix: \n",
      "[[ 1592   194]\n",
      " [  167 13047]]\n",
      "\n",
      "\n",
      "----------SVC---------\n",
      "percision is: 0.9965802222855514\n",
      "recall is: 0.9988574692944873\n",
      "roc_auc is: 0.9874046865510513\n",
      "confusion matrix: \n",
      "[[ 487   12]\n",
      " [   4 3497]]\n",
      "\n",
      "\n",
      "----------LogisticRegression---------\n",
      "percision is: 0.99375\n",
      "recall is: 0.9991431019708654\n",
      "roc_auc is: 0.97752746280908\n",
      "confusion matrix: \n",
      "[[ 477   22]\n",
      " [   3 3498]]\n",
      "\n",
      "\n",
      "----------KNeighborsClassifier---------\n",
      "percision is: 0.9965062111801242\n",
      "recall is: 0.733219080262782\n",
      "roc_auc is: 0.8575915040592467\n",
      "confusion matrix: \n",
      "[[ 490    9]\n",
      " [ 934 2567]]\n",
      "\n",
      "\n",
      "----------GaussianNB---------\n",
      "percision is: 0.978494623655914\n",
      "recall is: 0.8057697800628392\n",
      "roc_auc is: 0.8407606415344256\n",
      "confusion matrix: \n",
      "[[ 437   62]\n",
      " [ 680 2821]]\n",
      "\n",
      "\n",
      "----------DecisionTreeClassifier---------\n",
      "percision is: 0.987146529562982\n",
      "recall is: 0.987146529562982\n",
      "roc_auc is: 0.9484830844207696\n",
      "confusion matrix: \n",
      "[[ 454   45]\n",
      " [  45 3456]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [grid_SVC, grid_LR, grid_KNN, grid_NB, grid_tree]\n",
    "\n",
    "for model in models:\n",
    "    X_, y_ = X_train, y_train\n",
    "    get_performance(model,X_,y_)\n",
    "\n",
    "for model in models:\n",
    "    X_, y_ = X_valid, y_valid\n",
    "    get_performance(model,X_,y_)\n",
    "    \n",
    "#线型核的支持向量机和逻辑回归的表现尚可，两者相当，决策树次之，KNN和GsuaaianNB最差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存模型\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "model_SVC = joblib.dump(grid_SVC, 'model_SVC.pkl')\n",
    "model_LogisticRegression = joblib.dump(grid_LR, 'model_LogisticRegression.pkl')\n",
    "model_KNN = joblib.dump(grid_KNN, 'model_KNN.pkl')\n",
    "model_GaussianNB = joblib.dump(grid_NB, 'model_GaussianNB.pkl')\n",
    "model_DecisionTree = joblib.dump(grid_tree, 'model_DecesionTree.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "concated_dataset = pd.concat([dataset['content'],dataset['label']], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset.to_csv('concated_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_indices = pd.DataFrame(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_indices.to_csv('test_indices.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
