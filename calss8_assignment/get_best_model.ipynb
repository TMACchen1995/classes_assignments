{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "dataset = pd.read_csv('../sqlResult.csv', encoding = 'gb18030')\n",
    "dataset = dataset.fillna('')\n",
    "\n",
    "is_xinhua_news = dataset[dataset['source'].str.contains('新华')]\n",
    "# print(len(is_xinhua_news)/len(dataset))   -> 88.00%\n",
    "\n",
    "dataset = dataset.sample(60000)\n",
    "\n",
    "dataset['label'] = np.where(dataset['source'].str.contains('新华'),1,0)\n",
    "\n",
    "y = dataset['label'].values\n",
    "\n",
    "def cleaner_1(string):\n",
    "    if '新华社' in string:\n",
    "        string.replace('新华社', '')\n",
    "    elif '新华网' in string:\n",
    "        string.replace('新华网', '')\n",
    "    return string\n",
    "\n",
    "def cleaner_2(string): return ''.join(re.findall('[\\d|\\w]+', string))\n",
    "\n",
    "def cut(string): return ' '.join(jieba.cut(string))\n",
    "\n",
    "\n",
    "news_content = dataset['content'].apply(cleaner_1)\n",
    "news_content = news_content.apply(cleaner_2)\n",
    "news_content = news_content.apply(cut)\n",
    "\n",
    "dataset['content'] = news_content\n",
    "\n",
    "X = dataset['content'].values\n",
    "\n",
    "with open('../stop_words.txt', encoding = 'gbk') as f:\n",
    "\n",
    "    stopwords = f.read()\n",
    "\n",
    "stopwords_list = stopwords.splitlines()\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, norm='l2', min_df = 5, max_df = 0.7, ngram_range=(1, 2),stop_words=stopwords_list,max_features=35000)\n",
    "features = tfidf.fit_transform(X)\n",
    "\n",
    "indices = np.arange(len(X))\n",
    "\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "splitpoint1 = 0.25\n",
    "\n",
    "splitpoint2 = 0.05\n",
    "\n",
    "train_indices = indices[int(len(X)*splitpoint1):]\n",
    "\n",
    "valid_indices = indices[int(len(X)*splitpoint2):int(len(X)*splitpoint1)]\n",
    "\n",
    "test_indices = indices[:int(len(X)*splitpoint2)]\n",
    "\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test = (\n",
    "                                                        features[train_indices],\n",
    "                                                        features[valid_indices],\n",
    "                                                        features[test_indices],\n",
    "                                                        y[train_indices],\n",
    "                                                        y[valid_indices],\n",
    "                                                        y[test_indices]\n",
    "\n",
    "                                                        )\n",
    "\n",
    "X_train = X_train.toarray()\n",
    "X_valid = X_valid.toarray()\n",
    "X_test = X_test.toarray()\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def get_performance(clf, X_, y_):\n",
    "    y_hat = clf.predict(X_)\n",
    "    print('----------{}---------'.format(clf.__class__.__name__))\n",
    "    print('percision is: {}'.format(precision_score(y_, y_hat)))\n",
    "    print('recall is: {}'.format(recall_score(y_, y_hat)))\n",
    "    print('roc_auc is: {}'.format(roc_auc_score(y_, y_hat)))\n",
    "    print('confusion matrix: \\n{}'.format(confusion_matrix(y_, y_hat, labels=[0, 1])))\n",
    "    print('\\n')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "models = [\n",
    "#    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "   DecisionTreeClassifier(class_weight={0:5,1:4},criterion='entropy',max_features=5000),\n",
    "   LinearSVC(),\n",
    "   MultinomialNB(),\n",
    "   LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__  #获取各模型的名称。\n",
    "    model_name = model\n",
    "    X_, y_ = X_train, y_train\n",
    "    model_name.fit(X_,y_)\n",
    "    get_performance(model_name,X_,y_)\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__  #获取各模型的名称。\n",
    "    model_name = model\n",
    "    X_, y_ = X_valid, y_valid\n",
    "    get_performance(model_name,X_,y_)\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "DecisionTreeClassifier = models[0]\n",
    "model_DecisionTree = joblib.dump(DecisionTreeClassifier, 'model_DecesionTree.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset = pd.concat([dataset['content'],dataset['label']], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset.to_csv('concated_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecisionTreeClassifier和 LinearSVC（线性支持向量机）在训练集和测试集上取得的效果最好，\n",
    "#所以保存这两个模型。其中LinearSVC在X_valid表现更优一些。\n",
    "DecisionTreeClassifier = models[0]\n",
    "model_DecisionTree = joblib.dump(DecisionTreeClassifier, 'model_DecesionTree.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearSVC = models[1]\n",
    "model_LinearSVC = joblib.dump(LinearSVC, 'LinearSVC.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_indices = pd.DataFrame(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_indices.to_csv('test_indices.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
